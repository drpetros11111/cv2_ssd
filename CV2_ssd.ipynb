{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoieIM+qrzo4NYt9tL1Rrk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/cv2_ssd/blob/main/CV2_ssd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries"
      ],
      "metadata": {
        "id": "0HuO96ZKQJ5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "from data import BaseTransform, VOC_CLASSES as labelmap\n",
        "from ssd import build_ssd\n",
        "import imageio"
      ],
      "metadata": {
        "id": "0gZzS2rkQ3B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries\n",
        "This code snippet is importing necessary libraries for object detection, likely using a pre-trained SSD (Single Shot MultiBox Detector) model.\n",
        "\n",
        "\n",
        "---\n",
        "----\n",
        "Here's a step-by-step explanation:\n",
        "\n",
        "##import torch:\n",
        "This imports the PyTorch library, a fundamental library for deep learning and tensor computations.\n",
        "\n",
        "PyTorch is commonly used for building and training neural networks.\n",
        "\n",
        "------------\n",
        "##from torch.autograd import Variable:\n",
        "\n",
        "This imports the Variable class from the torch.autograd module.\n",
        "\n",
        "In older versions of PyTorch, Variable was used to wrap tensors and enable automatic differentiation.\n",
        "\n",
        "However, in newer versions, tensors themselves can track gradients, so Variable might be less relevant.\n",
        "\n",
        "---------------\n",
        "##import cv2:\n",
        "This imports the OpenCV (cv2) library, which is widely used for computer vision tasks like image processing, object detection, and video analysis.\n",
        "\n",
        "-------------------\n",
        "##from data import BaseTransform, VOC_CLASSES as labelmap:\n",
        "\n",
        "This imports BaseTransform and VOC_CLASSES from a custom module or file named data.\n",
        "\n",
        "BaseTransform is likely a class or function responsible for applying transformations to images (e.g., resizing, normalization) before feeding them into the SSD model.\n",
        "\n",
        "VOC_CLASSES is being imported and renamed to labelmap.\n",
        "\n",
        "This suggests that it holds a list of object classes the model is trained to detect (likely based on the PASCAL VOC dataset).\n",
        "\n",
        "-----------------------\n",
        "##from ssd import build_ssd:\n",
        "This imports the build_ssd function from a custom module or file named ssd.\n",
        "\n",
        "This function is likely responsible for constructing the SSD model architecture.\n",
        "\n",
        "------------------------\n",
        "##import imageio:\n",
        "This imports the imageio library, which is used for reading and writing various image and video formats.\n",
        "\n",
        "This library is probably here to load images or videos that will be processed by the object detection model.\n",
        "\n",
        "------------------------\n",
        "#In essence\n",
        "This block of code sets up the necessary tools for loading an SSD model, preprocessing images, and performing object detection using PyTorch and OpenCV in your Colab environment."
      ],
      "metadata": {
        "id": "D9NJ1q7ynB7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Detection Function"
      ],
      "metadata": {
        "id": "6xWzI6UfQqej"
      }
    },
    {
      "source": [
        "def detect(frame, net, transform):\n",
        "    # 1. Get frame dimensions\n",
        "    height, width = frame.shape[:2]\n",
        "\n",
        "    # 2. Transform the frame\n",
        "    frame_t = transform(frame)[0]\n",
        "\n",
        "    # 3. Convert to PyTorch tensor and format\n",
        "    x = torch.from_numpy(frame_t).permute(2, 0, 1)\n",
        "    x = Variable(x.unsqueeze(0))\n",
        "\n",
        "    # 4. Make prediction\n",
        "    y = net(x)\n",
        "    detections = y.data\n",
        "\n",
        "    # 5. Create scale for bounding boxes\n",
        "    scale = torch.Tensor([width, height, width, height])\n",
        "\n",
        "    # 6. Loop through detections\n",
        "    for i in range(detections.size(1)):\n",
        "        j = 0\n",
        "        while detections[0, i, j, 0] >= 0.6:\n",
        "            # 7. Get coordinates and draw bounding box\n",
        "            pt = (detections[0, i, j, 1:] * scale).numpy()\n",
        "            cv2.rectangle(frame, (int(pt[0]), int(pt[1])), (int(pt[2]), int(pt[3])), (255, 0, 0), 2)\n",
        "\n",
        "            # 8. Add label text\n",
        "            cv2.putText(frame, labelmap[i - 1], (int(pt[0]), int(pt[1])), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            j += 1\n",
        "\n",
        "    # 9. Return the frame with detections\n",
        "    return frame"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "a3w1BZjvpA4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Break down the detect function\n",
        "\n",
        "----\n",
        "---\n",
        "\n",
        "## Get Frame Dimensions:\n",
        "It gets the height and width of the input\n",
        "frame using frame.shape[:2].\n",
        "\n",
        "--------------------\n",
        "##Transform the Frame:\n",
        "Applies a transformation (likely resizing and normalization) to the frame using the provided transform function.\n",
        "\n",
        "--------------------------\n",
        "##Convert to PyTorch Tensor and Format:\n",
        "\n",
        "Converts the transformed frame to a PyTorch tensor using torch.from_numpy().\n",
        "\n",
        "-----------------\n",
        "##Reorders the dimensions (channels, height, width) using permute(2, 0, 1).\n",
        "\n",
        "----------------------\n",
        "##Adds a batch dimension using unsqueeze(0).\n",
        "\n",
        "Wraps the tensor in a Variable (might be redundant in newer PyTorch versions).\n",
        "\n",
        "-------------------\n",
        "##Make Prediction:\n",
        "Passes the formatted tensor x through the neural network net to get the detection output y.\n",
        "\n",
        "Extracts the detection data using y.data.\n",
        "\n",
        "--------------------\n",
        "##Create Scale for Bounding Boxes:\n",
        "Creates a scaling tensor to convert the normalized bounding box coordinates to the original frame's dimensions.\n",
        "\n",
        "---------------------\n",
        "##Loop through Detections:\n",
        "Iterates through the detected objects.\n",
        "\n",
        "--------------------------\n",
        "##Get Coordinates and Draw Bounding Box:\n",
        "Extracts the bounding box coordinates (pt) from the detection data, scales them using the scale tensor, and converts them to NumPy array.\n",
        "\n",
        "----------------------\n",
        "##Draws a rectangle on the frame using cv2.\n",
        "\n",
        "rectangle with the calculated coordinates, color (blue - (255, 0, 0)), and thickness.\n",
        "\n",
        "-----------------------------\n",
        "##Add Label Text\n",
        "Adds the label of the detected object (from labelmap) to the frame using cv2.putText near the bounding box.\n",
        "\n",
        "It specifies font, size, color, thickness, and line type.\n",
        "\n",
        "-------------------------\n",
        "##Return the Frame with Detections:\n",
        "\n",
        "Returns the modified frame with the drawn bounding boxes and labels.\n",
        "\n",
        "------------------------------\n",
        "--------------------\n",
        "\n",
        "#In summary\n",
        "This function takes an image frame, a pre-trained object detection model (net), and a transformation function (transform) as input.\n",
        "\n",
        "It preprocesses the frame, makes predictions using the model, and then draws bounding boxes and labels around the detected objects before returning the modified frame."
      ],
      "metadata": {
        "id": "-uifYwfEoyeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the SSD neural network"
      ],
      "metadata": {
        "id": "r4IKnNFtU3F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = build_ssd('test')\n",
        "net.load_state_dict(torch.load('ssd300_mAP_77.43_v2.pth', map_location = lambda storage, loc: storage))"
      ],
      "metadata": {
        "id": "nuW8_lvTVA9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the SSD network -from pretrained\n",
        "\n",
        "-----------------\n",
        "---------------------\n",
        "##net = build_ssd('test'):\n",
        "\n",
        "This line creates an instance of the SSD (Single Shot MultiBox Detector) model.\n",
        "\n",
        "build_ssd is a function (likely defined in your ssd module) that constructs the SSD model architecture.\n",
        "\n",
        "The argument 'test' is passed to build_ssd, indicating that the model is being built for testing/inference purposes (as opposed to training).\n",
        "\n",
        "----------------------\n",
        "##net.load_state_dict(torch.load('ssd300_mAP_77.43_v2.pth', map_location = lambda storage, loc: storage)):\n",
        "\n",
        "This line loads pre-trained weights into the SSD model.\n",
        "\n",
        "###torch.load('ssd300_mAP_77.43_v2.pth', map_location = lambda storage, loc: storage):\n",
        "\n",
        "This part loads the saved state dictionary (containing model weights and biases) from the file ssd300_mAP_77.43_v2.pth.\n",
        "\n",
        "The map_location argument is used to handle loading the model on different devices (e.g., CPU instead of GPU). In this case, it's using a lambda function to keep the storage location as is.\n",
        "\n",
        "###net.load_state_dict(...):\n",
        "\n",
        "This part takes the loaded state dictionary and assigns the weights and biases to the corresponding parameters within the net model instance.\n",
        "\n",
        "------------------\n",
        "------------------------\n",
        "#In essence:\n",
        "\n",
        "This code snippet first builds an SSD model for testing and then loads pre-trained weights from a file into the model.\n",
        "\n",
        "This allows you to use a pre-trained model for object detection without having to train it from scratch. This is a common practice in deep learning to leverage existing models and save training time."
      ],
      "metadata": {
        "id": "3daOMKQ2VcZP"
      }
    }
  ]
}